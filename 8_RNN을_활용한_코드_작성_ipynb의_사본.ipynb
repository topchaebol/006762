{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8. RNN을 활용한 코드 작성.ipynb의 사본",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/topchaebol/006762/blob/master/8_RNN%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EC%BD%94%EB%93%9C_%EC%9E%91%EC%84%B1_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8KpNAuX_6hW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "161b53a0-0703-48f3-bb24-494cb57a7ba1"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "class Data:\n",
        "  def __init__(self, max_features=20000, maxlen=80):\n",
        "    np_load_old = np.load\n",
        "    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "    np.load = np_load_old\n",
        "    \n",
        "    x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "    x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "    self.x_train, self.y_train = x_train, y_train\n",
        "    self.x_test, self.y_test = x_test, y_test\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-yBOeEBA4Da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "96fe3e2e-3673-4297-a6ec-32c3654722dd"
      },
      "source": [
        "\n",
        "data = Data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mac_36tgBDtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "09477bd3-1db7-4997-f20f-86cf295b7a45"
      },
      "source": [
        "data.x_train[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyOG2uc5C7m9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIZ3YFPoCCA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN_LSTM(models.Model):\n",
        "  def __init__(self, max_features, maxlen):\n",
        "    x = layers.Input((maxlen,))\n",
        "    h = layers.Embedding(max_features, 128)(x)\n",
        "    h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(h)\n",
        "    y = layers.Dense(1, activation='sigmoid')(h)\n",
        "    super().__init__(x, y)\n",
        "    \n",
        "    self.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "class Machine:\n",
        "  def __init__(self, max_features=20000, maxlen=80):\n",
        "    self.data = Data(max_features, maxlen)\n",
        "    self.model = RNN_LSTM(max_features, maxlen)\n",
        "    \n",
        "  def run(self, epochs=3, batch_size=32):\n",
        "    data = self.data\n",
        "    model = self.model\n",
        "    print(\"Train stage\")\n",
        "    print(\"=\" * 10)\n",
        "    \n",
        "    model.fit(data.x_train, data.y_train,\n",
        "             batch_size = batch_size,\n",
        "             epochs = epochs,\n",
        "             validation_data = (data.x_test, data.y_test)\n",
        "             )\n",
        "    score, acc = model.evalute(data.x_test, data.y_test,\n",
        "                              batch_size = batch_size)\n",
        "    \n",
        "    print(\"acc: {}, loss: {}\".format(acc,score))\n",
        "    ## shorturl.at/dRT35"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKSUD4GZEGIS",
        "colab_type": "code",
        "outputId": "b1e101a0-0af7-4e1b-a2d7-75c23b07b114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "source": [
        "m = Machine()\n",
        "m.run()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0705 07:51:46.621652 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0705 07:51:46.653100 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0705 07:51:46.663063 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0705 07:51:46.815685 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0705 07:51:46.832435 140624371828608 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0705 07:51:47.255093 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0705 07:51:47.283502 140624371828608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0705 07:51:47.290958 140624371828608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train stage\n",
            "==========\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 149s 6ms/step - loss: 0.4564 - acc: 0.7857 - val_loss: 0.4013 - val_acc: 0.8196\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 148s 6ms/step - loss: 0.2991 - acc: 0.8780 - val_loss: 0.3796 - val_acc: 0.8332\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 148s 6ms/step - loss: 0.2140 - acc: 0.9160 - val_loss: 0.4111 - val_acc: 0.8245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-46c5b21d2b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-d43050a62a20>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m              \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m              )\n\u001b[0;32m---> 28\u001b[0;31m     score, acc = model.evalute(data.x_test, data.y_test,\n\u001b[0m\u001b[1;32m     29\u001b[0m                               batch_size = batch_size)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RNN_LSTM' object has no attribute 'evalute'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjTrFNGPENXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}